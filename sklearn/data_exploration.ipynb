{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <font color=red> Data Exploration\n",
    "#### This notebook aims to find out useful features \n",
    "### <font color=blue> Rules :\n",
    "#### Since we are a lot contributing to the notebook, please comment your code and use explicit variable names\n",
    "#### Do not modify the raw data as others would like to work on it\n",
    "#### Only modify your section (copy-paste others code if needed) so that no clashes occur when pulling/pushing on remote repository"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font color=green>Hugo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Specific imports in your section"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font color=green>Nicolas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Specific imports in your section"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font color=green>Mohamed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sklearn as skl\n",
    "import nltk\n",
    "from tokenizer import Tokenizer\n",
    "import seaborn as sns\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Getting the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train_fname = 'train.csv'\n",
    "#test_fname = 'test.csv'\n",
    "X = pd.read_csv(train_fname,header=None)\n",
    "y = pd.read_csv(train_fname, header=None)[0]\n",
    "#X_test = pd.read_csv(test_fname, header=None)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X.columns = ['label', 'content']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    3066\n",
       "1    1349\n",
       "Name: 0, dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[6, 8, 11, 12, 15, 18, 23, 27, 28, 29]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "index_1 = [index for index in range(X.shape[0]) if y[index]==1]\n",
    "index_1[0:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Some insulting comments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6     \"who told you that....stupid ask yourself who ...\n",
       "8                             \"You're an idiot baldo. \"\n",
       "11    \"You show your stupidity and ignorance each an...\n",
       "12    \"Wait until you are a minority in your own red...\n",
       "15    \"Its \"faggot\" you ignorant fuck plus what you ...\n",
       "18     \"Get thatdick outta your mouth so you can talk.\"\n",
       "23    \"Judging by your prior posts listed in your pr...\n",
       "27    \"RYAN...........GO BACK TO SUCKING YOUR MOTHER...\n",
       "28                                  \"Your are an idiot\"\n",
       "29    \"Very sorry I mentioned it.\\xa0 Just keep bitc...\n",
       "Name: content, dtype: object"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.content[index_1[:10]] # Wow violent lui ... hahaa"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Adding some features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X['char_count'] = np.array([len(x) for x in X.content])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4415, 3)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>content</th>\n",
       "      <th>char_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>\"Imagine being able say, you know what, no san...</td>\n",
       "      <td>684</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>\"\"But Jack from Raleigh wasn't done. He came b...</td>\n",
       "      <td>365</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>\"the Star box allows you to link your comment ...</td>\n",
       "      <td>175</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>\"Cheney,Rush,Nugent.The list is endless.\"</td>\n",
       "      <td>41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>\"Obama....I'm blow'n mo smoke up yo arses........</td>\n",
       "      <td>181</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   label                                            content  char_count\n",
       "0      0  \"Imagine being able say, you know what, no san...         684\n",
       "1      0  \"\"But Jack from Raleigh wasn't done. He came b...         365\n",
       "2      0  \"the Star box allows you to link your comment ...         175\n",
       "3      0          \"Cheney,Rush,Nugent.The list is endless.\"          41\n",
       "4      0  \"Obama....I'm blow'n mo smoke up yo arses........         181"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Tokenizing Stemming and Cleaning a sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# To Keep updated\n",
    "TOKENS = [\n",
    "    ### Replacements first ###\n",
    "    ('WHITE_SPACE'     , r\"(\\\\\\\\xc2|\\\\\\\\xa0|\\\\xa0|\\\\xa1|\\\\xa3|\\\\xa9|\\\\r|\\\\ufeff|\\\\u2013|\\\\u2016|\\\\u200f|\\\\u2665|\\\\U0001f308|\\\\U0001f3e9|\\\\U0001f48b|\\\\\\\\|\\\\|&nbsp|&amp|=|\\\"\\\"|\\\"|\\\\u2018|\\\\u2019)\", r\" \"),\n",
    "    ('LETTER_A'        , r\"(\\\\xe1|\\\\xe3|\\\\xe0|\\\\xc2|\\\\u1ef1|\\\\u0105|\\\\u1eb7|\\\\xe5|\\\\xe4)\", r\"a\"),\n",
    "    ('LETTER_E'        , r\"(\\\\xe9|\\\\xe8|\\\\u1ec3|\\\\u1ec5|\\\\u1ebf|\\\\u0119)\", r\"e\"),\n",
    "    ('LETTER_I'        , r\"(\\\\xed)\", r\"i\"),\n",
    "    ('LETTER_O'        , r\"(\\\\x00 |\\\\xf8|\\\\xf6|\\\\xf3)\", r\"o\"),\n",
    "    ('LETTER_U'        , r\"(\\\\xfa|\\\\xdc|\\\\xfc|\\\\u1ee9|\\\\u0169)\", r\"u\"),\n",
    "    ('LETTER_Y'        , r\"(\\\\xfd)\", r\"u\"),\n",
    "    ('LETTER_C'        , r\"(\\\\xe7|\\\\u0107)\", r\"c\"),\n",
    "    ('LETTER_Z'        , r\"(\\\\u017a|\\\\u017e|\\\\u017c)\", r\"z\"),\n",
    "    ('PONCT_!'        , r\"(\\\\u203d)\", r\"!\"),\n",
    "    ### Tokens ###\n",
    "    ('PUNCT'      , r\"(!+|\\?+|\\.+)\", r\" \\1 \"),\n",
    "    ('NIL'          , r\"\\'|,\", r\" \"),\n",
    "    ('SMILEY'       , r\"(\\:\\w+\\:|\\<[\\/\\\\]?3|[\\(\\)\\\\\\D|\\*\\$][\\-\\^]?[\\:\\;\\=]|[\\:\\;\\=B8][\\-\\^]?[3DOPp\\@\\$\\*\\\\\\)\\(\\/\\|])(?=\\s|[\\!\\.\\?]|$)|xD|XD\", r\" \\0 \"),\n",
    "    ('PUNCT'      , r\"(;+|\\,+|\\)+|\\(+)\", r\" \\1 \"),\n",
    "    ('BREAK'        , r\"(\\\\n|\\\\\\n)\", r\" \"),\n",
    "#    ('QUOTE'      , r\"(\\\"|\\')+(\\w+)(\\\"|\\')+\", \"QUOTE\"), # A améliorer pour mettre la citation entre deux <QUOTE>\n",
    "    ('BEGIN_WHITESPACE' , r\"^\\s+\", r\"\"),\n",
    "    ('END_WHITESPACE' , r\"\\s+$\", r\"\"),\n",
    "    ('WHITESPACES' , r\"\\s+\", r\" \")\n",
    "]\n",
    "\n",
    "# Ca déconne\n",
    "INSULTS = [\n",
    "    ### Insults Replacment ###\n",
    "    ('FUCK'    , r\"f(.*ck|u.*k|uc.*)(.?ng*)\", r\" fuck \"),# fuck/fucking style\n",
    "    ('FUCK_2'    , r\"f(.*ck|u.*k|uc.*)((\\s)*you|.*er)*\", r\" fuck you \"),#fuck you + fuck your XXXer\n",
    "    ('FUCK_3'    , r\"(\\w+-)*f(.*ck|u.*k|uc.*)((\\s)*you|.?ng|.*er)*\", r\" mother fuck \"),# compouned fuck # mother fuck plutot ?\n",
    "    # Replace above regex \"mother fuck\" by \"you fuck\" since personal insult ?\n",
    "    ('ASSHOLE',  r\"a.*ole*s*\", r\" asshole \"),# ass hole and its versions\n",
    "    ('STALK',  r\"stalk(in*g*|ers?)?\", r\" stalk \"),\n",
    "    ('STUPID',  r\"(\\$|s)tupi?d\", r\" stupid \"),\n",
    "    ('SHIT',  r\"sh?(.*ty*|i.*)\", r\" shit \")\n",
    "]\n",
    "\n",
    "RANDOM = [\n",
    "    ### Random Replacement ###\n",
    "    ('LAUGH',  r\"\\b(?:a*(?:ha)+h?|(?:l+o+)+l+)\\b\", r\" laugh \"), # matches laughs such as \"hahaha\" or \"lolll\"\n",
    "    ('DOLLAR',  r\"[0-9]+k?\\s?\\$?\", r\" dollar \"),\n",
    "    ('DATE',  r\"[0-9]+th(\\s?of)?(\\s\\w+)?\", r\" date \"),# eg : 18th or \"18th of Month\"\n",
    "    ('YEAR',  r\"[0-9]{4}?\", r\" year \"),\n",
    "    ('NUMBER',  r\"[0-9]{2}\", r\" number \"),\n",
    "    ('LOVE',  r\"<3\", r\" love \"),\n",
    "    ('PSEUDO',  r\"@\\s?\\w+\", r\" pseudo \"),\n",
    "    ('URL',  r\"(http:)?(\\/\\/)?((www\\.)?\\w+\\.\\w+)\\/?(\\w+.\\w+)?\", r\" url \")   \n",
    "]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <font color=red>UTILISER LES DEUX DICO AU DESSUS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "myTokenizer = Tokenizer(TOKENS)\n",
    "#myReplacer = Tokenizer(REPLACERS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4415,)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.content.values.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(numpy.ndarray, str)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(X.content.values), type(X.content.values[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\"\"But Jack from Raleigh wasn\\'t done. He came back with this bit of furious grammatical genius:\"\\\\n\"Holy hell, Jack. Calm down.\"\\\\n\\\\nGOD D@MN HILARIOUS!\\\\n\\\\nWho writes your material GraziD?  \\\\n\\\\nMM never even acknowledged we were here (well accept when Uber ticked him off)  GraziD not only interacts with us, he calls you dumb when you\\'re being dumb... right beeaner?\"'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.content.values[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "tokens = myTokenizer.tokenize(X.content.values[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(['But',\n",
       "  'Jack',\n",
       "  'from',\n",
       "  'Raleigh',\n",
       "  'wasn',\n",
       "  't',\n",
       "  'done',\n",
       "  '.',\n",
       "  'He',\n",
       "  'came',\n",
       "  'back',\n",
       "  'with'],\n",
       " 75)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokens[:12], len(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "new_string = myTokenizer.reconstruct(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'but jack from raleigh wasn t done . he came back with this bit of furious grammat geniu \\x00 n holi hell jack . calm down . n ngod d@mn hilari ! n nwho write your materi grazid ? n nmm never even acknowledg we were here ( well accept when uber tick him off ) grazid not only interact with us he call you dumb when you re being dumb ... right beeaner ?'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_string"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tokenizing Stemming and Cleaning the DataSet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ '\"Imagine being able say, you know what, no sanctions, no forever hearings on IEAA regulations, no more hiding\\\\xa0under\\\\xa0the pretense of friendly nuclear energy. \\\\xa0You have 2 days to; \\\\xa0i.e. \\\\xa0let in the inspectors, quit killing the civilians, respect the border and rights of your neighboring country, \\\\xa0or we ( whoever we are) will shut off your nuclear plant, your monitoring system and whatever else we fancy, like your water\\\\xa0treatment\\\\xa0plants and early warning sandstorm system and the traffic lights of all major cities...\\\\xa0\\\\nand yes..( pinky finger to lip edge) so your teenagers revolt and topple your regime... \\\\xa0disconnect ... FACEBOOK.... buwhahjahahaha.\"',\n",
       "       '\"\"But Jack from Raleigh wasn\\'t done. He came back with this bit of furious grammatical genius:\"\\\\n\"Holy hell, Jack. Calm down.\"\\\\n\\\\nGOD D@MN HILARIOUS!\\\\n\\\\nWho writes your material GraziD?  \\\\n\\\\nMM never even acknowledged we were here (well accept when Uber ticked him off)  GraziD not only interacts with us, he calls you dumb when you\\'re being dumb... right beeaner?\"',\n",
       "       '\"the Star box allows you to link your comment to Facebook and Twitter. You can go to your profile and change settings. If you click back on yellow star it will return to grey\"',\n",
       "       '\"Cheney,Rush,Nugent.The list is endless.\"',\n",
       "       '\"Obama....I\\'m blow\\'n mo smoke up yo arses.....Anyone wonder why the Dem\\'s as such sheep.... It must be some DNA thing not to be able to do simple math.\\\\\\\\n\\\\\\\\nI just don\\'t get it....\"'], dtype=object)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_list = X.content.values\n",
    "X_list[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4415,)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_list.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tokens_data = myTokenizer.tokenize_array(X_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4415"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(tokens_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "new_X_list = []\n",
    "for tokens in tokens_data:\n",
    "    new_X_list.append(myTokenizer.reconstruct(tokens))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['imagin being abl say you know what no sanction no forev hear on ieaa regul no more hide under the pretens of friend nuclear energi . you have 2 day t \\x00 i . e . let in the inspector quit kill the civilian respect the border and right of your neighbor countri or we ( whoever we are ) will shut off your nuclear plant your monitor system and whatev els we fanci like your water treatment plant and earli warn sandstorm system and the traffic light of all major citi ... nand yes .. ( pinki finger to lip edg ) so your teenag revolt and toppl your regim ... disconnect ... facebook .... buwhahjahahaha .',\n",
       " 'but jack from raleigh wasn t done . he came back with this bit of furious grammat geniu \\x00 n holi hell jack . calm down . n ngod d@mn hilari ! n nwho write your materi grazid ? n nmm never even acknowledg we were here ( well accept when uber tick him off ) grazid not only interact with us he call you dumb when you re being dumb ... right beeaner ?',\n",
       " 'the star box allow you to link your comment to facebook and twitter . you can go to your profil and chang set . if you click back on yellow star it will return to grey',\n",
       " 'cheney rush nugent . the list is endless .',\n",
       " 'obama .... i m blow n mo smoke up yo ars ..... anyon wonder why the dem s as such sheep .... it must be some dna thing not to be abl to do simpl math . n ni just don t get it ....']"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_X_list[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4415"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(new_X_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X_new = np.asarray(new_X_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4415,)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_new.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X['processed'] = X_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>content</th>\n",
       "      <th>char_count</th>\n",
       "      <th>processed</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>\"Imagine being able say, you know what, no san...</td>\n",
       "      <td>684</td>\n",
       "      <td>imagin being abl say you know what no sanction...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>\"\"But Jack from Raleigh wasn't done. He came b...</td>\n",
       "      <td>365</td>\n",
       "      <td>but jack from raleigh wasn t done . he came ba...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>\"the Star box allows you to link your comment ...</td>\n",
       "      <td>175</td>\n",
       "      <td>the star box allow you to link your comment to...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>\"Cheney,Rush,Nugent.The list is endless.\"</td>\n",
       "      <td>41</td>\n",
       "      <td>cheney rush nugent . the list is endless .</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>\"Obama....I'm blow'n mo smoke up yo arses........</td>\n",
       "      <td>181</td>\n",
       "      <td>obama .... i m blow n mo smoke up yo ars ........</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   label                                            content  char_count  \\\n",
       "0      0  \"Imagine being able say, you know what, no san...         684   \n",
       "1      0  \"\"But Jack from Raleigh wasn't done. He came b...         365   \n",
       "2      0  \"the Star box allows you to link your comment ...         175   \n",
       "3      0          \"Cheney,Rush,Nugent.The list is endless.\"          41   \n",
       "4      0  \"Obama....I'm blow'n mo smoke up yo arses........         181   \n",
       "\n",
       "                                           processed  \n",
       "0  imagin being abl say you know what no sanction...  \n",
       "1  but jack from raleigh wasn t done . he came ba...  \n",
       "2  the star box allow you to link your comment to...  \n",
       "3         cheney rush nugent . the list is endless .  \n",
       "4  obama .... i m blow n mo smoke up yo ars ........  "
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <font color=red> TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn import cross_validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = cross_validation.train_test_split(X.processed, X.label, test_size=0.4, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.feature_extraction.text import CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "count_vect = CountVectorizer()\n",
    "X_train_counts = count_vect.fit_transform(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2649, 9294)"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_counts.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tf_transformer = TfidfTransformer(use_idf=False).fit(X_train_counts)\n",
    "X_train_tf = tf_transformer.transform(X_train_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2649, 9294)"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_tf.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classifiers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "text_clf = Pipeline([('vect', CountVectorizer()),\n",
    "                    ('tfidf', TfidfTransformer()),\n",
    "                    ('clf', LogisticRegression())\n",
    "                    ])\n",
    "                    \n",
    "_ = text_clf.fit(X_train, y_train)\n",
    "predicted = text_clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.79      0.96      0.86      1211\n",
      "          1       0.82      0.43      0.57       555\n",
      "\n",
      "avg / total       0.80      0.79      0.77      1766\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn import metrics\n",
    "print(metrics.classification_report(y_test, predicted))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### NAIVE-BAYES : ACCURACY = 0.78"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LOGISTIC REGRESSION = 0.80"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Adding general Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class BadWordCounter():\n",
    "    def __init__(self):\n",
    "        with open(\"my_badlist.txt\") as f:\n",
    "            badwords = [l.strip() for l in f.readlines()]\n",
    "        self.badwords_ = badwords\n",
    "\n",
    "    def get_feature_names(self):\n",
    "        return np.array(['n_words', 'n_chars', 'allcaps', 'max_len',\n",
    "            'mean_len', '@', '!', 'spaces', 'bad_ratio', 'n_bad',\n",
    "            'capsratio'])\n",
    "\n",
    "    def fit(self, documents, y=None):\n",
    "        return self\n",
    "\n",
    "    def transform(self, documents):\n",
    "        ## some handcrafted features!\n",
    "        n_words = [len(c.split()) for c in documents]\n",
    "        n_chars = [len(c) for c in documents]\n",
    "        # number of uppercase words\n",
    "        allcaps = [np.sum([w.isupper() for w in comment.split()])\n",
    "               for comment in documents]\n",
    "        # longest word\n",
    "        max_word_len = [np.max([len(w) for w in c.split()]) for c in documents]\n",
    "        # average word length\n",
    "        mean_word_len = [np.mean([len(w) for w in c.split()])\n",
    "                                            for c in documents]\n",
    "        # number of google badwords:\n",
    "        n_bad = [np.sum([c.lower().count(w) for w in self.badwords_])\n",
    "                                                for c in documents]\n",
    "        exclamation = [c.count(\"!\") for c in documents]\n",
    "        addressing = [c.count(\"@\") for c in documents]\n",
    "        spaces = [c.count(\" \") for c in documents]\n",
    "\n",
    "        allcaps_ratio = np.array(allcaps) / np.array(n_words, dtype=np.float)\n",
    "        bad_ratio = np.array(n_bad) / np.array(n_words, dtype=np.float)\n",
    "\n",
    "        return np.array([n_words, n_chars, allcaps, max_word_len,\n",
    "            mean_word_len, exclamation, addressing, spaces, bad_ratio, n_bad,\n",
    "            allcaps_ratio]).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "bad_counter = BadWordCounter()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "features = bad_counter.transform(X.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4415, 11)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn import cross_validation\n",
    "from sklearn.cross_validation import cross_val_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = cross_validation.train_test_split(features, y, test_size=0.4, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train.shape, X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "clf_1 = SVC(kernel='linear', C=1)\n",
    "clf_2 = LinearRegression()\n",
    "cross_validation.cross_val_score(clf_1, features, y, cv=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
